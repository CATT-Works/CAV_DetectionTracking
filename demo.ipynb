{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import socket\n",
    "import json\n",
    "\n",
    "from time import time\n",
    "from cav.objects import Object, BoundingBox, ObjectType\n",
    "from cav.parameters import Parameters\n",
    "\n",
    "from cav.visualization import Map, plotBoxes, bsmImg\n",
    "\n",
    "\n",
    "# Deep sort imports\n",
    "from deep_sort import nn_matching\n",
    "from deep_sort.tracker import Tracker\n",
    "from deep_sort.detection import Detection\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BSM Server configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUSH_BSM = True # If true, bsms are being pushed to the server\n",
    "\n",
    "HOST = '128.8.215.213'   # The server's hostname or IP address\n",
    "PORT = 65432        # The port used by the server\n",
    "DATA_BUFF = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUnction that sends data\n",
    "def sendBsm(s, bsm):\n",
    "    data = {\n",
    "        'mode' : 'push',\n",
    "        'msg' : bsm\n",
    "    }\n",
    "    \n",
    "    msg = json.dumps(data)\n",
    "    msg = str.encode(msg)\n",
    "    s.sendall(msg)\n",
    "    data = s.recv(1024)  \n",
    "    return data    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageEncoder(object):\n",
    "\n",
    "    def __init__(self, checkpoint_filename, input_name=\"images\",\n",
    "                 output_name=\"features\"):\n",
    "        self.session = tf.Session()\n",
    "        with tf.gfile.GFile(checkpoint_filename, \"rb\") as file_handle:\n",
    "            graph_def = tf.GraphDef()\n",
    "            graph_def.ParseFromString(file_handle.read())\n",
    "        tf.import_graph_def(graph_def, name=\"net\")\n",
    "        self.input_var = tf.get_default_graph().get_tensor_by_name(\n",
    "            \"net/%s:0\" % input_name)\n",
    "        self.output_var = tf.get_default_graph().get_tensor_by_name(\n",
    "            \"net/%s:0\" % output_name)\n",
    "\n",
    "        assert len(self.output_var.get_shape()) == 2\n",
    "        assert len(self.input_var.get_shape()) == 4\n",
    "        self.feature_dim = self.output_var.get_shape().as_list()[-1]\n",
    "        self.image_shape = self.input_var.get_shape().as_list()[1:]\n",
    "\n",
    "    def __call__(self, data_x, batch_size=32):\n",
    "        out = np.zeros((len(data_x), self.feature_dim), np.float32)\n",
    "        _run_in_batches(\n",
    "            lambda x: self.session.run(self.output_var, feed_dict=x),\n",
    "            {self.input_var: data_x}, out, batch_size)\n",
    "        return out\n",
    "\n",
    "    \n",
    "def create_box_encoder(model_filename, input_name=\"images\",\n",
    "                       output_name=\"features\", batch_size=32):\n",
    "    image_encoder = ImageEncoder(model_filename, input_name, output_name)\n",
    "    image_shape = image_encoder.image_shape\n",
    "\n",
    "    def encoder(image, boxes):\n",
    "        image_patches = []\n",
    "        for box in boxes:\n",
    "            patch = extract_image_patch(image, box, image_shape[:2])\n",
    "            if patch is None:\n",
    "                print(\"WARNING: Failed to extract image patch: %s.\" % str(box))\n",
    "                patch = np.random.uniform(\n",
    "                    0., 255., image_shape).astype(np.uint8)\n",
    "            image_patches.append(patch)\n",
    "        image_patches = np.asarray(image_patches)\n",
    "        return image_encoder(image_patches, batch_size)\n",
    "\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_in_batches(f, data_dict, out, batch_size):\n",
    "    data_len = len(out)\n",
    "    num_batches = int(data_len / batch_size)\n",
    "\n",
    "    s, e = 0, 0\n",
    "    for i in range(num_batches):\n",
    "        s, e = i * batch_size, (i + 1) * batch_size\n",
    "        batch_data_dict = {k: v[s:e] for k, v in data_dict.items()}\n",
    "        out[s:e] = f(batch_data_dict)\n",
    "    if e < len(out):\n",
    "        batch_data_dict = {k: v[e:] for k, v in data_dict.items()}\n",
    "        out[e:] = f(batch_data_dict)\n",
    "        \n",
    "        \n",
    "def extract_image_patch(image, bbox, patch_shape):\n",
    "    \"\"\"Extract image patch from bounding box.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : ndarray\n",
    "        The full image.\n",
    "    bbox : array_like\n",
    "        The bounding box in format (x, y, width, height).\n",
    "    patch_shape : Optional[array_like]\n",
    "        This parameter can be used to enforce a desired patch shape\n",
    "        (height, width). First, the `bbox` is adapted to the aspect ratio\n",
    "        of the patch shape, then it is clipped at the image boundaries.\n",
    "        If None, the shape is computed from :arg:`bbox`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ndarray | NoneType\n",
    "        An image patch showing the :arg:`bbox`, optionally reshaped to\n",
    "        :arg:`patch_shape`.\n",
    "        Returns None if the bounding box is empty or fully outside of the image\n",
    "        boundaries.\n",
    "\n",
    "    \"\"\"\n",
    "    bbox = np.array(bbox)\n",
    "    if patch_shape is not None:\n",
    "        # correct aspect ratio to patch shape\n",
    "        target_aspect = float(patch_shape[1]) / patch_shape[0]\n",
    "        new_width = target_aspect * bbox[3]\n",
    "        bbox[0] -= (new_width - bbox[2]) / 2\n",
    "        bbox[2] = new_width\n",
    "\n",
    "    # convert to top left, bottom right\n",
    "    bbox[2:] += bbox[:2]\n",
    "    bbox = bbox.astype(np.int)\n",
    "\n",
    "    # clip at image boundaries\n",
    "    bbox[:2] = np.maximum(0, bbox[:2])\n",
    "    bbox[2:] = np.minimum(np.asarray(image.shape[:2][::-1]) - 1, bbox[2:])\n",
    "    if np.any(bbox[:2] >= bbox[2:]):\n",
    "        return None\n",
    "    sx, sy, ex, ey = bbox\n",
    "    image = image[sy:ey, sx:ex]\n",
    "    image = cv2.resize(image, tuple(patch_shape[::-1]))\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER_PATH = \"./deep_sort_network/mars-small128.pb\"\n",
    "ENCODER_BATCH_SIZE = 32\n",
    "ENCODER_INPUT_NAME = \"images\"\n",
    "ENCODER_OUTPUT_NAME = \"features\"\n",
    "\n",
    "image_encoder = ImageEncoder(ENCODER_PATH, ENCODER_INPUT_NAME, ENCODER_OUTPUT_NAME)\n",
    "encoder = create_box_encoder(ENCODER_PATH, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_cosine_distance = 0.2\n",
    "nn_budget = 100\n",
    "\n",
    "metric = nn_matching.NearestNeighborDistanceMetric(\n",
    "    \"cosine\", max_cosine_distance, nn_budget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create object detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cav.detection import ObjectDetector\n",
    "import cv2\n",
    "MODEL_PATH = '/home/catt/Documents/CarDetection/old_20190521/faster_rcnn_inception_v2/fine_tuned_model/frozen_inference_graph.pb'\n",
    "od = ObjectDetector(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create params and map objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Parameters()\n",
    "params.generateParameters('./config/params.json')\n",
    "mymap = Map('./images/CATT_satelite.jpg', './config/icons.json', params)\n",
    "plt.imshow(mymap.getMap(), interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPARE_VISUALIZATION = False\n",
    "\n",
    "\n",
    "VIDEO_X = 240\n",
    "VIDEO_Y = 320\n",
    "FRAMES_SEC = 6\n",
    "\n",
    "MAX_BOXES_TO_DRAW = 20\n",
    "MIN_SCORE_THRESH = 0.5\n",
    "IOU_COMMON_THRESHOLD = 0.50\n",
    "NOT_DETECTED_TRHESHOLD = 1\n",
    "\n",
    "BSM_X = 0\n",
    "\n",
    "FINAL_X = VIDEO_X + mymap.getMap().shape[1] + BSM_X\n",
    "FINAL_Y = VIDEO_Y \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('rtmp://170.93.143.157/rtplive/c5ff65d2008900a1004f823633235daa')\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "\n",
    "if PREPARE_VISUALIZATION:\n",
    "    if RESIZE:\n",
    "        out = cv2.VideoWriter('Test1_output.avi',fourcc, 2*FRAMES_SEC, (int(FINAL_X/2), int(FINAL_Y/2)))\n",
    "    else:\n",
    "        out = cv2.VideoWriter('Test1_output.avi',fourcc, 2*FRAMES_SEC, (int(FINAL_X), int(FINAL_Y)))\n",
    "else:\n",
    "    out = None\n",
    "\n",
    "\n",
    "objects = []\n",
    "\n",
    "results = []\n",
    "colors = {}\n",
    "\n",
    "\n",
    "\n",
    "tracker = Tracker(metric)\n",
    "\n",
    "i = 0\n",
    "t = time()\n",
    "\n",
    "with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "    s.connect((HOST, PORT))\n",
    "    while cap.isOpened():\n",
    "        sys.stdout.write(\"Processing Frame {}     \\r\".format(i))\n",
    "        ret, image = cap.read()\n",
    "\n",
    "        boxes, scores, classes = od.detect(image)\n",
    "        if len(boxes) >= 1:\n",
    "\n",
    "            boxes_array = [[box.xLeft, box.yTop, box.xRight - box.xLeft, box.yBottom - box.yTop] for box in boxes]\n",
    "            boxes_array = np.array(boxes_array)\n",
    "            bgr_image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "            features = encoder(bgr_image, boxes_array)\n",
    "            detections = []\n",
    "\n",
    "            for box, score, objClass, f_vector in zip(boxes, scores, classes, features):\n",
    "                detection = Detection(\n",
    "                    [box.xLeft, box.yTop, box.xRight - box.xLeft, box.yBottom - box.yTop], #BBox\n",
    "                    score, f_vector,\n",
    "                    objClass\n",
    "                )\n",
    "                detection.bbox = box\n",
    "                detections.append(detection)\n",
    "\n",
    "            tracker.predict()\n",
    "            tracker.update(detections)                \n",
    "\n",
    "        plotboxes = []\n",
    "        plotcolors = []\n",
    "        objects = []\n",
    "\n",
    "        if len(tracker.tracks) >= 1:\n",
    "            for track in tracker.tracks:\n",
    "                if not track.is_confirmed() or track.time_since_update > 1:\n",
    "                    continue\n",
    "\n",
    "                if False:\n",
    "                    bbox = track.to_tlwh()\n",
    "                    results.append([\n",
    "                        i, track.track_id, bbox[0], bbox[1], bbox[2], bbox[3]])\n",
    "\n",
    "\n",
    "                obj = track.trackedObject\n",
    "\n",
    "                if obj is not None:\n",
    "                    plotbox = obj.bboxes[-1]\n",
    "                    plotbox.trackId = track.track_id\n",
    "                    plotboxes.append(plotbox)\n",
    "                    plotcolors.append(obj.color)\n",
    "                    objects.append(obj)\n",
    "\n",
    "            if len(plotboxes) >= 1:\n",
    "                vid = plotBoxes(image, plotboxes, colors=plotcolors)\n",
    "            else:\n",
    "                vid = image.copy()\n",
    "                mapimg = mymap.getMap()\n",
    "\n",
    "            if PREPARE_VISUALIZATION:\n",
    "                mapimg = mymap.addObjects(objects)        \n",
    "        elif PREPARE_VISUALIZATION:\n",
    "                vid = image.copy()\n",
    "                mapimg = mymap.getMap()\n",
    "\n",
    "\n",
    "        # Adding map\n",
    "        if PREPARE_VISUALIZATION:\n",
    "            final_image = np.zeros((FINAL_Y, FINAL_X,3),dtype=np.uint8)\n",
    "\n",
    "            final_image[:VIDEO_Y, :VIDEO_X, :] = vid\n",
    "            final_image[:mapimg.shape[0], VIDEO_X:VIDEO_X + mapimg.shape[1], :] = mapimg  \n",
    "\n",
    "        if (BSM_X > 0) & PREPARE_VISUALIZATION:\n",
    "            if len(objects) > 0:\n",
    "                obj = objects[0]\n",
    "                color = obj.color\n",
    "                bsmimg = bsmImg(obj.getBsm(params=params), framecolor=color)\n",
    "                final_image[:bsmimg.shape[0], VIDEO_X + mapimg.shape[1]:, :] =  bsmimg\n",
    "\n",
    "            if len(objects) > 1:\n",
    "                obj = objects[1]\n",
    "                color = obj.color\n",
    "                bsmimg = bsmImg(obj.getBsm(params=params), framecolor=color)\n",
    "                #final_image[bsmimg.shape[0]+10:2*bsmimg.shape[0]+10, VIDEO_X + mapimg.shape[1]:, :] =  bsmimg\n",
    "\n",
    "        if PREPARE_VISUALIZATION & True: # Resize image\n",
    "            width = int(final_image.shape[1] / 2)\n",
    "            height = int(final_image.shape[0] / 2)\n",
    "            dim = (width, height)\n",
    "            # resize image\n",
    "            final_image = cv2.resize(final_image, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "        if PREPARE_VISUALIZATION:\n",
    "            cv2.imwrite('./tmp/im_{}.jpg'.format(str(i).zfill(4)), final_image)\n",
    "            out.write(final_image)            \n",
    "\n",
    "            \n",
    "        bsm_list = []\n",
    "        for obj in objects:\n",
    "            bsm_list.append(obj.getBsm(retDic = False, params=params, roundValues = True, includeNone = False))\n",
    "        data = sendBsm(s, json.dumps(bsm_list))\n",
    "        print (\"Response: {}\\n\".format(data))            \n",
    "                        \n",
    "        i = i+1\n",
    "        if i > 10* FRAMES_SEC:\n",
    "            if False:\n",
    "                f = open('tmp_tracking_results_demo.txt', 'w')\n",
    "                for row in results:\n",
    "                    print('%d,%d,%.2f,%.2f,%.2f,%.2f,1,-1,-1,-1' % (\n",
    "                        row[0], row[1], row[2], row[3], row[4], row[5]),file=f)        \n",
    "            break\n",
    "\n",
    "                        \n",
    "t = time() - t                             \n",
    "print('\\n\\n{} frames done in {:.1f} seconds ({:.2f} frames/sec)'.format(\n",
    "    i, t, i/t))                             \n",
    "cap.release()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker.tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tracker.tracks[0]\n",
    "o = t.trackedObject\n",
    "t.is_confirmed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o.bboxes[-1].params_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o.bboxes[-1].lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = ObjectType(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
