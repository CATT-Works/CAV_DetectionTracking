{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic example\n",
    "This is a basic notebook, used only to detect and track objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../..')\n",
    "\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle \n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import socket\n",
    "import json\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from time import time\n",
    "from cav.objects import Object, BoundingBox, ObjectType\n",
    "from cav.parameters import Parameters\n",
    "\n",
    "from cav.visualization import Map, plotBoxes, bsmImg\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Deep sort imports\n",
    "from deep_sort import nn_matching\n",
    "from deep_sort.tracker import Tracker\n",
    "from deep_sort.detection import Detection\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import ImageEncoder, create_box_encoder, extract_image_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER_PATH = \"../../deep_sort_network/mars-small128.pb\"\n",
    "ENCODER_BATCH_SIZE = 32\n",
    "ENCODER_INPUT_NAME = \"images\"\n",
    "ENCODER_OUTPUT_NAME = \"features\"\n",
    "\n",
    "image_encoder = ImageEncoder(ENCODER_PATH, ENCODER_INPUT_NAME, ENCODER_OUTPUT_NAME)\n",
    "encoder = create_box_encoder(ENCODER_PATH, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_cosine_distance = 0.2\n",
    "nn_budget = 100\n",
    "\n",
    "metric = nn_matching.NearestNeighborDistanceMetric(\n",
    "    \"cosine\", max_cosine_distance, nn_budget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create object detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cav.detection import ObjectDetector\n",
    "import cv2\n",
    "MODEL_PATH = '../../../../ObjectDetection/models/frcnn/inference/saved_model/'\n",
    "\n",
    "od = ObjectDetector(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_FOLDER = '../frames/{}/frames_raw/'.format(os.getcwd().split('/')[-1])\n",
    "CUT_UPPER = 0 # Delete first X rows\n",
    "SAVE_DETECTIONS = './data/detections.p'\n",
    "VIDEO_FILE = '/data/MoveOver/Videos/tmp/D8_581-4-2021-04-06 FHWA.mp4'\n",
    "\n",
    "# Create folders\n",
    "Path(FRAME_FOLDER).mkdir(parents=True, exist_ok=True)\n",
    "Path(os.sep.join(SAVE_DETECTIONS.split(os.sep)[:-1])).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Store path to the video file for later\n",
    "pickle.dump(VIDEO_FILE, open('./data/videopath.p', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(VIDEO_FILE)\n",
    "\n",
    "tracker = Tracker(metric)\n",
    "\n",
    "objects = []\n",
    "\n",
    "results = []\n",
    "colors = {}\n",
    "\n",
    "\n",
    "save_detections = {}    \n",
    "\n",
    "# Delete old files\n",
    "filenames = glob.glob(os.path.join(FRAME_FOLDER, '*.jpg'))\n",
    "for f in filenames:\n",
    "    os.remove(f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "i = 0\n",
    "t = time()\n",
    "\n",
    "while cap.isOpened():\n",
    "    video_x = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) \n",
    "    video_y = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) - CUT_UPPER     \n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    out = cv2.VideoWriter('Test1_output.avi',cv2.VideoWriter_fourcc(*'DIVX'), fps, (video_x, video_y))\n",
    "\n",
    "    frame_timeStamp = i/fps\n",
    "\n",
    "    t2 = time() - t\n",
    "    sys.stdout.write('{} frames done in {:.1f} seconds ({:.2f} frames/sec)    \\r'.format(\n",
    "        i, t2, i/t2))                   \n",
    "    i += 1\n",
    "    \n",
    "    ret, image = cap.read()\n",
    "\n",
    "    if CUT_UPPER > 0:\n",
    "        image = image[CUT_UPPER:, :, :]\n",
    "    \n",
    "    boxes, scores, classes = od.detect(image, timestamp=frame_timeStamp)\n",
    "    if SAVE_DETECTIONS is not None:\n",
    "        save_detections[i] = (boxes, scores, classes)\n",
    "        \n",
    "        \n",
    "    if len(boxes) >= 1:\n",
    "        boxes_array = [[box.xLeft, box.yTop, box.xRight - box.xLeft, box.yBottom - box.yTop] for box in boxes]\n",
    "        boxes_array = np.array(boxes_array)\n",
    "        bgr_image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "        features = encoder(bgr_image, boxes_array)\n",
    "        detections = []\n",
    "\n",
    "        for box, score, objClass, f_vector in zip(boxes, scores, classes, features):\n",
    "            detection = Detection(\n",
    "                [box.xLeft, box.yTop, box.xRight - box.xLeft, box.yBottom - box.yTop], #BBox\n",
    "                score, f_vector,\n",
    "                objClass\n",
    "            )\n",
    "            detection.bbox = box\n",
    "            detections.append(detection)\n",
    "\n",
    "        tracker.predict()\n",
    "        tracker.update(detections)   \n",
    "    else:\n",
    "        tracker.predict()\n",
    "\n",
    "    plotboxes = []\n",
    "    plotcolors = []\n",
    "    objects = []\n",
    "\n",
    "    if len(tracker.tracks) >= 1:\n",
    "        for track in tracker.tracks:\n",
    "            if not track.is_confirmed() or track.time_since_update > 1:\n",
    "                continue\n",
    "\n",
    "            if False:\n",
    "                bbox = track.to_tlwh()\n",
    "                results.append([\n",
    "                    i, track.track_id, bbox[0], bbox[1], bbox[2], bbox[3]])\n",
    "\n",
    "\n",
    "            obj = track.trackedObject\n",
    "\n",
    "            if obj is not None:\n",
    "                if obj.color is None:\n",
    "                    obj.color = (randint(0, 255), randint(0, 255), randint(0, 255))       \n",
    "                plotbox = obj.bboxes[-1]\n",
    "                plotbox.trackId = track.track_id\n",
    "                plotboxes.append(plotbox)\n",
    "                plotcolors.append(obj.color)\n",
    "                objects.append(obj)\n",
    "\n",
    "\n",
    "    if len(plotboxes) >= 1:\n",
    "        vid = plotBoxes(image, plotboxes, colors=plotcolors)\n",
    "    else:\n",
    "        vid = image.copy()\n",
    "        \n",
    "    cv2.imwrite(os.path.join(FRAME_FOLDER, 'im_{}.jpg'.format(str(i).zfill(5))), vid)\n",
    "    #out.write(vid)            \n",
    "         \n",
    "    if i > fps * 60 * 45:\n",
    "        break\n",
    "                        \n",
    "t = time() - t                             \n",
    "print('\\n\\n{} frames done in {:.1f} seconds ({:.2f} frames/sec)'.format(\n",
    "    i, t, i/t))                             \n",
    "cap.release()\n",
    "\n",
    "if SAVE_DETECTIONS is not None:\n",
    "    pickle.dump(save_detections, open(SAVE_DETECTIONS,'wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_DETECTIONS is not None:\n",
    "    pickle.dump(save_detections, open(SAVE_DETECTIONS,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('({}x{}), {:.1f} fps'.format(video_x, video_y, fps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import generate_video\n",
    "generate_video(fps = fps, outputFile='output_video_test2.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
