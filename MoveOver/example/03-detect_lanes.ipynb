{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move over project demo\n",
    "This notebook is the first attempt of applying detection and tracking system for move over projets\n",
    "- objects are detected and tracked\n",
    "- objects are visualized in the map\n",
    "- objects at lanes are counted\n",
    "- objects that changed lanes are counted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "sys.path.insert(0,'../..')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import socket\n",
    "import json\n",
    "\n",
    "from time import time\n",
    "from cav.objects import Object, BoundingBox, ObjectType\n",
    "from cav.parameters import Parameters\n",
    "from cav.lanes import Lanes\n",
    "\n",
    "from cav.visualization import Map, plotBoxes\n",
    "\n",
    "# Deep sort imports\n",
    "from deep_sort import nn_matching\n",
    "from deep_sort.tracker import Tracker\n",
    "from deep_sort.detection import Detection\n",
    "%matplotlib inline \n",
    "\n",
    "#from icecream import ic\n",
    "import pandas as pd\n",
    "\n",
    "from helper import generate_video\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import ImageEncoder, create_box_encoder, extract_image_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER_PATH = \"./../../deep_sort_network/mars-small128.pb\"\n",
    "ENCODER_BATCH_SIZE = 32\n",
    "ENCODER_INPUT_NAME = \"images\"\n",
    "ENCODER_OUTPUT_NAME = \"features\"\n",
    "\n",
    "image_encoder = ImageEncoder(ENCODER_PATH, ENCODER_INPUT_NAME, ENCODER_OUTPUT_NAME)\n",
    "encoder = create_box_encoder(ENCODER_PATH, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_cosine_distance = 0.2\n",
    "nn_budget = 100\n",
    "\n",
    "metric = nn_matching.NearestNeighborDistanceMetric(\n",
    "    \"cosine\", max_cosine_distance, nn_budget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create object detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cav.detection import ObjectDetector\n",
    "import cv2\n",
    "MODEL_PATH = '../../../../ObjectDetection/models/frcnn/inference/saved_model/'\n",
    "#od = ObjectDetector(MODEL_PATH)\n",
    "od = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create params and map objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Parameters()\n",
    "params.generateParameters('./params.json')\n",
    "mymap = Map('./images/SkyView.jpg', './icons_simple.json', params)\n",
    "plt.imshow(mymap.getMap(), interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lane Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cav.lanes import Lanes\n",
    "lanes_controller = Lanes('./images/mask.png', params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saved detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/{}'.format(os.getcwd().split('/')[-1])\n",
    "\n",
    "SAVE_DETECTIONS = f'{DATA_PATH}/detections.p'\n",
    "FRAME_FOLDER = os.path.join(DATA_PATH, 'frames_raw/')\n",
    "VIDEO_FILE = pickle.load(open(f'{DATA_PATH}/videopath.p', 'rb'))\n",
    "print ('Video path:', VIDEO_FILE)\n",
    "\n",
    "save_detections = pickle.load(open(SAVE_DETECTIONS,'rb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logging parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_LOG = None #### Saves logs with all detected objects (path to file or none)\n",
    "#SAVE_LOG = 'test_log_20201028.csv'\n",
    "\n",
    "SAVE_LANES = None ###### Saves info about lanes\n",
    "SAVE_LANES = './data/lanes_detections.csv' ###### Saves info about lanes\n",
    "\n",
    "SKIP_FIRST = 0 # How many seconds in the beginning should be skipped\n",
    "#SKIP_FIRST = 6\n",
    "#SKIP_FIRST = (25*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(VIDEO_FILE) \n",
    "FRAMES_SEC = cap.get(cv2.CAP_PROP_FPS)\n",
    "VIDEO_X = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) \n",
    "VIDEO_Y = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) \n",
    "\n",
    "\n",
    "MAX_BOXES_TO_DRAW = 100\n",
    "MIN_SCORE_THRESH = 0.5\n",
    "IOU_COMMON_THRESHOLD = 0.50\n",
    "NOT_DETECTED_TRHESHOLD = 1\n",
    "\n",
    "MAPSHAPE = mymap.getMap().shape\n",
    "print ('Y dimension of map is {:.3f} larger than Y dimension of the video'\n",
    "      .format(MAPSHAPE[0] / VIDEO_Y))\n",
    "\n",
    "MAP_RESIZE = 3\n",
    "\n",
    "print ('Y dimension of map is {:.3f} larger than Y dimension of the video. Size of the map is reduced {} times.'\n",
    "      .format(MAPSHAPE[0] / VIDEO_Y, MAP_RESIZE))\n",
    "\n",
    "\n",
    "FINAL_X = VIDEO_X + int(MAPSHAPE[1] / MAP_RESIZE)\n",
    "FINAL_Y = max(VIDEO_Y, int(MAPSHAPE[0] / MAP_RESIZE))\n",
    "\n",
    "print ('Video size: [{}, {}], Final size: [{}, {}]'\n",
    "      .format(VIDEO_X, VIDEO_Y, FINAL_X, FINAL_Y))\n",
    "\n",
    "RESIZE = False\n",
    "\n",
    "\n",
    "CROP_VID = False\n",
    "VID_LEFT = 0\n",
    "VID_RIGHT = 1920\n",
    "VID_UP = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (MAPSHAPE[0] / VIDEO_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(VIDEO_FILE) \n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "\n",
    "out = None\n",
    "\n",
    "objects = []\n",
    "\n",
    "results = []\n",
    "colors = {}\n",
    "\n",
    "\n",
    "tracker = Tracker(metric)\n",
    "\n",
    "\n",
    "\n",
    "nr_skipped = 0\n",
    "i = 0\n",
    "t = time()\n",
    "\n",
    "with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "    \n",
    "    if SAVE_LANES is not None:\n",
    "        logfile_lanes = open('{}'.format(SAVE_LANES), 'w')\n",
    "\n",
    "    while cap.isOpened():\n",
    "        t2 = time() - t\n",
    "        sys.stdout.write('{} frames done in {:.1f} seconds ({:.2f} frames/sec)    \\r'.format(\n",
    "            i, t2, i/t2))                   \n",
    "        #sys.stdout.write(\"Processing Frame {}     \\r\".format(i))\n",
    "        \n",
    "        \n",
    "        frame_timeStamp = i/FRAMES_SEC\n",
    "        \n",
    "        ret, image = cap.read()\n",
    "\n",
    "        if i < SKIP_FIRST * FRAMES_SEC:\n",
    "            i += 1\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        if CROP_VID:\n",
    "            image = image[VID_UP:, VID_LEFT:VID_RIGHT, :]\n",
    "        \n",
    "        #boxes, scores, classes = od.detect(image, timestamp=frame_timeStamp)\n",
    "        boxes, scores, classes = save_detections[i+1] \n",
    "        \n",
    "        if len(boxes) >= 1:\n",
    "            for box in boxes:\n",
    "                box.updateParams(params)\n",
    "                \n",
    "            boxes_array = [[box.xLeft, box.yTop, box.xRight - box.xLeft, box.yBottom - box.yTop] for box in boxes]\n",
    "            boxes_array = np.array(boxes_array)\n",
    "            bgr_image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "            features = encoder(bgr_image, boxes_array)\n",
    "            detections = []\n",
    "\n",
    "            for box, score, objClass, f_vector in zip(boxes, scores, classes, features):\n",
    "                detection = Detection(\n",
    "                    [box.xLeft, box.yTop, box.xRight - box.xLeft, box.yBottom - box.yTop], #BBox\n",
    "                    score, f_vector,\n",
    "                    objClass\n",
    "                )\n",
    "                detection.bbox = box\n",
    "                detections.append(detection)\n",
    "\n",
    "            tracker.predict()\n",
    "            tracker.update(detections)                \n",
    "            \n",
    "        else:\n",
    "            tracker.predict()\n",
    "            \n",
    "        plotboxes = []\n",
    "        plotcolors = []\n",
    "        objects = []\n",
    "\n",
    "        if len(tracker.tracks) >= 1:\n",
    "            for track in tracker.tracks:\n",
    "                if not track.is_confirmed() or track.time_since_update >= 1:\n",
    "                    continue\n",
    "\n",
    "                if False:\n",
    "                    bbox = track.to_tlwh()\n",
    "                    results.append([\n",
    "                        i, track.track_id, bbox[0], bbox[1], bbox[2], bbox[3]])\n",
    "\n",
    "\n",
    "                obj = track.trackedObject\n",
    "\n",
    "                if obj is not None:\n",
    "                    if obj.color is None:\n",
    "                        obj.color = (randint(0, 255), randint(0, 255), randint(0, 255))                        \n",
    "                    plotbox = obj.bboxes[-1]\n",
    "                    plotbox.trackId = track.track_id\n",
    "                    plotboxes.append(plotbox)\n",
    "                    plotcolors.append(obj.color)\n",
    "                    objects.append(obj)\n",
    "                    \n",
    "                    if SAVE_LANES is not None:\n",
    "                        lane = lanes_controller.addObject(obj)\n",
    "                        #if (lane > 0) & (SAVE_LANES is not None):\n",
    "                        if SAVE_LANES is not None:\n",
    "                            log_line = '{},{},{}'.format(i, lane, obj.getParams(asCsv=True, speedLookback = 10))\n",
    "                            print(log_line,file=logfile_lanes)                              \n",
    "\n",
    "                                                         \n",
    "            if len(plotboxes) >= 1:\n",
    "                vid = plotBoxes(image, plotboxes, colors=plotcolors)\n",
    "            else:\n",
    "                vid = image.copy()\n",
    "                #mapimg = mymap.getMap()\n",
    "            cv2.imwrite(os.path.join(FRAME_FOLDER, 'im_{}.jpg'.format(str(i).zfill(6))), vid)\n",
    "\n",
    "\n",
    "                \n",
    "        if len(objects) > 0:\n",
    "                                \n",
    "            if SAVE_LOG is not None:\n",
    "                logfile = open('./logs/{}'.format(SAVE_LOG, 'w'))\n",
    "                for obj in objects:\n",
    "                    line = '{},{},{}'.format(i,time(),obj.getParams(asCsv=true))                               \n",
    "                    print(line,file=logfile)                    \n",
    "                                \n",
    "        i = i+1\n",
    "        #if i > (60*24+SKIP_FIRST) * FRAMES_SEC:\n",
    "        if False:\n",
    "            break\n",
    "                  \n",
    "            \n",
    "                        \n",
    "t = time() - t                             \n",
    "print('\\n\\n{} frames done in {:.1f} seconds ({:.2f} frames/sec)'.format(\n",
    "    i, t, i/t))                             \n",
    "cap.release()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Video\n",
    "No need to do this here, first we should analyze lanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('({}x{}), {:.1f} fps'.format(FINAL_X, FINAL_Y, FRAMES_SEC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate_video(fps = FRAMES_SEC, outputFile='videos/output_.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
