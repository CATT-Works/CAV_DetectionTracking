{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic example\n",
    "This is a basic notebook, used only to detect and track objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pickle \n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import socket\n",
    "import json\n",
    "\n",
    "from time import time\n",
    "from cav.objects import Object, BoundingBox, ObjectType\n",
    "from cav.parameters import Parameters\n",
    "\n",
    "from cav.visualization import Map, plotBoxes, bsmImg\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Deep sort imports\n",
    "from deep_sort import nn_matching\n",
    "from deep_sort.tracker import Tracker\n",
    "from deep_sort.detection import Detection\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import ImageEncoder, create_box_encoder, extract_image_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER_PATH = \"./deep_sort_network/mars-small128.pb\"\n",
    "ENCODER_BATCH_SIZE = 32\n",
    "ENCODER_INPUT_NAME = \"images\"\n",
    "ENCODER_OUTPUT_NAME = \"features\"\n",
    "\n",
    "image_encoder = ImageEncoder(ENCODER_PATH, ENCODER_INPUT_NAME, ENCODER_OUTPUT_NAME)\n",
    "encoder = create_box_encoder(ENCODER_PATH, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_cosine_distance = 0.2\n",
    "nn_budget = 100\n",
    "\n",
    "metric = nn_matching.NearestNeighborDistanceMetric(\n",
    "    \"cosine\", max_cosine_distance, nn_budget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create object detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cav.detection import ObjectDetector\n",
    "import cv2\n",
    "#MODEL_PATH = '../../ObjectDetection/models/frcnn_old/inference/saved_model/'\n",
    "MODEL_PATH = '../../ObjectDetection/models/frcnn/inference/saved_model/'\n",
    "\n",
    "od = ObjectDetector(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_FOLDER = './MoveOver/PAI81_66/frames/frames_raw/'\n",
    "SAVE_LOG = None #### Saves logs with all detected objects (path to file or none)\n",
    "#SAVE_LOG = 'test_log_20201028.csv'\n",
    "\n",
    "CUT_UPPER = 0 # Delete first X rows\n",
    "#SAVE_DETECTIONS = None #### Saves everything in a dictionary\n",
    "SAVE_DETECTIONS = './MoveOver/PAI81_66/detections.p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('/data/MoveOver/Videos/PA/D8_81-66-2021-02-23 FHWA.mp4')\n",
    "#cap = cv2.VideoCapture('/data/MoveOver/Videos/PA/8 D8_30-PA 501-2021-03-02 FHWA.mp4')\n",
    "\n",
    "tracker = Tracker(metric)\n",
    "\n",
    "objects = []\n",
    "\n",
    "results = []\n",
    "colors = {}\n",
    "\n",
    "\n",
    "save_detections = {}    \n",
    "\n",
    "# Delete old files\n",
    "filenames = glob.glob(os.path.join(FRAME_FOLDER, '*.jpg'))\n",
    "for f in filenames:\n",
    "    os.remove(f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "i = 0\n",
    "t = time()\n",
    "\n",
    "while cap.isOpened():\n",
    "    video_x = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) \n",
    "    video_y = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) - CUT_UPPER     \n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    out = cv2.VideoWriter('Test1_output.avi',cv2.VideoWriter_fourcc(*'DIVX'), fps, (video_x, video_y))\n",
    "\n",
    "    frame_timeStamp = i/fps\n",
    "\n",
    "    t2 = time() - t\n",
    "    sys.stdout.write('{} frames done in {:.1f} seconds ({:.2f} frames/sec)    \\r'.format(\n",
    "        i, t2, i/t2))                   \n",
    "    i += 1\n",
    "    \n",
    "    ret, image = cap.read()\n",
    "\n",
    "    if CUT_UPPER > 0:\n",
    "        image = image[CUT_UPPER:, :, :]\n",
    "    \n",
    "    boxes, scores, classes = od.detect(image, timestamp=frame_timeStamp)\n",
    "    if SAVE_DETECTIONS is not None:\n",
    "        save_detections[i] = (boxes, scores, classes)\n",
    "        \n",
    "        \n",
    "    if len(boxes) >= 1:\n",
    "        boxes_array = [[box.xLeft, box.yTop, box.xRight - box.xLeft, box.yBottom - box.yTop] for box in boxes]\n",
    "        boxes_array = np.array(boxes_array)\n",
    "        bgr_image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "        features = encoder(bgr_image, boxes_array)\n",
    "        detections = []\n",
    "\n",
    "        for box, score, objClass, f_vector in zip(boxes, scores, classes, features):\n",
    "            detection = Detection(\n",
    "                [box.xLeft, box.yTop, box.xRight - box.xLeft, box.yBottom - box.yTop], #BBox\n",
    "                score, f_vector,\n",
    "                objClass\n",
    "            )\n",
    "            detection.bbox = box\n",
    "            detections.append(detection)\n",
    "\n",
    "        tracker.predict()\n",
    "        tracker.update(detections)   \n",
    "    else:\n",
    "        tracker.predict()\n",
    "\n",
    "    plotboxes = []\n",
    "    plotcolors = []\n",
    "    objects = []\n",
    "\n",
    "    if len(tracker.tracks) >= 1:\n",
    "        for track in tracker.tracks:\n",
    "            if not track.is_confirmed() or track.time_since_update > 1:\n",
    "                continue\n",
    "\n",
    "            if False:\n",
    "                bbox = track.to_tlwh()\n",
    "                results.append([\n",
    "                    i, track.track_id, bbox[0], bbox[1], bbox[2], bbox[3]])\n",
    "\n",
    "\n",
    "            obj = track.trackedObject\n",
    "\n",
    "            if obj is not None:\n",
    "                if obj.color is None:\n",
    "                    obj.color = (randint(0, 255), randint(0, 255), randint(0, 255))       \n",
    "                plotbox = obj.bboxes[-1]\n",
    "                plotbox.trackId = track.track_id\n",
    "                plotboxes.append(plotbox)\n",
    "                plotcolors.append(obj.color)\n",
    "                objects.append(obj)\n",
    "\n",
    "\n",
    "    if len(plotboxes) >= 1:\n",
    "        vid = plotBoxes(image, plotboxes, colors=plotcolors)\n",
    "    else:\n",
    "        vid = image.copy()\n",
    "        \n",
    "    cv2.imwrite(os.path.join(FRAME_FOLDER, 'im_{}.jpg'.format(str(i).zfill(5))), vid)\n",
    "    #out.write(vid)            \n",
    "         \n",
    "    if i > fps * 60 * 45:\n",
    "        break\n",
    "                        \n",
    "t = time() - t                             \n",
    "print('\\n\\n{} frames done in {:.1f} seconds ({:.2f} frames/sec)'.format(\n",
    "    i, t, i/t))                             \n",
    "cap.release()\n",
    "\n",
    "if SAVE_DETECTIONS is not None:\n",
    "    pickle.dump(save_detections, open(SAVE_DETECTIONS,'wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('({}x{}), {:.1f} fps'.format(video_x, video_y, fps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import generate_video\n",
    "generate_video(fps = fps, outputFile='output_video_test2.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use saved detections - test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_detections = pickle.load(open(SAVE_DETECTIONS,'rb'))\n",
    "save_detections[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('/data/MoveOver/Videos/PA/D8_81-66-2021-02-23 FHWA.mp4')\n",
    "\n",
    "tracker = Tracker(metric)\n",
    "\n",
    "objects = []\n",
    "\n",
    "results = []\n",
    "colors = {}\n",
    "\n",
    "\n",
    "\n",
    "# Delete old files\n",
    "filenames = glob.glob(os.path.join(FRAME_FOLDER, '*.jpg'))\n",
    "for f in filenames:\n",
    "    os.remove(f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "i = 0\n",
    "t = time()\n",
    "\n",
    "while cap.isOpened():\n",
    "    video_x = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) \n",
    "    video_y = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) - CUT_UPPER     \n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    out = cv2.VideoWriter('Test1_output.avi',cv2.VideoWriter_fourcc(*'DIVX'), fps, (video_x, video_y))\n",
    "\n",
    "\n",
    "    t2 = time() - t\n",
    "    sys.stdout.write('{} frames done in {:.1f} seconds ({:.2f} frames/sec)    \\r'.format(\n",
    "        i, t2, i/t2))                   \n",
    "    i += 1\n",
    "    \n",
    "    ret, image = cap.read()\n",
    "\n",
    "    if CUT_UPPER > 0:\n",
    "        image = image[CUT_UPPER:, :, :]\n",
    "    \n",
    "    #boxes, scores, classes = od.detect(image)\n",
    "    boxes, scores, classes = save_detections[i]    \n",
    "\n",
    "    if len(boxes) >= 1:\n",
    "        boxes_array = [[box.xLeft, box.yTop, box.xRight - box.xLeft, box.yBottom - box.yTop] for box in boxes]\n",
    "        boxes_array = np.array(boxes_array)\n",
    "        bgr_image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "        features = encoder(bgr_image, boxes_array)\n",
    "        detections = []\n",
    "\n",
    "        for box, score, objClass, f_vector in zip(boxes, scores, classes, features):\n",
    "            detection = Detection(\n",
    "                [box.xLeft, box.yTop, box.xRight - box.xLeft, box.yBottom - box.yTop], #BBox\n",
    "                score, f_vector,\n",
    "                objClass\n",
    "            )\n",
    "            detection.bbox = box\n",
    "            detections.append(detection)\n",
    "\n",
    "        tracker.predict()\n",
    "        tracker.update(detections)   \n",
    "    else:\n",
    "        tracker.predict()\n",
    "\n",
    "    plotboxes = []\n",
    "    plotcolors = []\n",
    "    objects = []\n",
    "\n",
    "    if len(tracker.tracks) >= 1:\n",
    "        for track in tracker.tracks:\n",
    "            if not track.is_confirmed() or track.time_since_update > 1:\n",
    "                continue\n",
    "\n",
    "            if False:\n",
    "                bbox = track.to_tlwh()\n",
    "                results.append([\n",
    "                    i, track.track_id, bbox[0], bbox[1], bbox[2], bbox[3]])\n",
    "\n",
    "\n",
    "            obj = track.trackedObject\n",
    "\n",
    "            if obj is not None:\n",
    "                if obj.color is None:\n",
    "                    obj.color = (randint(0, 255), randint(0, 255), randint(0, 255))       \n",
    "                plotbox = obj.bboxes[-1]\n",
    "                plotbox.trackId = track.track_id\n",
    "                plotboxes.append(plotbox)\n",
    "                plotcolors.append(obj.color)\n",
    "                objects.append(obj)\n",
    "\n",
    "\n",
    "    if len(plotboxes) >= 1:\n",
    "        vid = plotBoxes(image, plotboxes, colors=plotcolors)\n",
    "    else:\n",
    "        vid = image.copy()\n",
    "        \n",
    "    cv2.imwrite(os.path.join(FRAME_FOLDER, 'im_{}.jpg'.format(str(i).zfill(5))), vid)\n",
    "    #out.write(vid)            \n",
    "         \n",
    "    if i > fps * 60 * 30:\n",
    "        break\n",
    "                        \n",
    "t = time() - t                             \n",
    "print('\\n\\n{} frames done in {:.1f} seconds ({:.2f} frames/sec)'.format(\n",
    "    i, t, i/t))                             \n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
