{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import socket\n",
    "import json\n",
    "\n",
    "from time import time\n",
    "from cav.objects import Object, BoundingBox, ObjectType\n",
    "from cav.parameters import Parameters\n",
    "\n",
    "from cav.visualization import Map, plotBoxes, bsmImg\n",
    "\n",
    "\n",
    "# Deep sort imports\n",
    "from deep_sort import nn_matching\n",
    "from deep_sort.tracker import Tracker\n",
    "from deep_sort.detection import Detection\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print (tf.__version__)\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BSM Server configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUSH_BSM = False # If true, bsms are being pushed to the server\n",
    "\n",
    "#HOST = '128.8.215.214'   # The server's hostname or IP address\n",
    "#HOST = '127.0.0.1'   # The server's hostname or IP address\n",
    "HOST = '10.228.16.251'\n",
    "PORT = 65432        # The port used by the server\n",
    "DATA_BUFF = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUnction that sends data\n",
    "def sendBsm(s, bsm):\n",
    "    data = {\n",
    "        'mode' : 'push',\n",
    "        'msg' : bsm\n",
    "    }\n",
    "    \n",
    "    msg = json.dumps(data)\n",
    "    msg = str.encode(msg)\n",
    "    s.sendall(msg)\n",
    "    data = s.recv(1024)  \n",
    "    return data    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import ImageEncoder, create_box_encoder, extract_image_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageEncoder(object):\n",
    "\n",
    "    def __init__(self, checkpoint_filename, input_name=\"images\",\n",
    "                 output_name=\"features\"):\n",
    "        \n",
    "        self.tf_version = int(tf.__version__.split('.')[0])\n",
    "        \n",
    "        if self.tf_version == 1:\n",
    "            self.session = tf.Session()\n",
    "            with tf.io.gfile.GFile(checkpoint_filename, \"rb\") as file_handle:\n",
    "                graph_def = tf.GraphDef()\n",
    "                graph_def.ParseFromString(file_handle.read())\n",
    "            \n",
    "        else:\n",
    "            self.session = tf.compat.v1.Session()\n",
    "            \n",
    "            with tf.io.gfile.GFile(checkpoint_filename, \"rb\") as file_handle:\n",
    "                graph_def = tf.compat.v1.GraphDef() \n",
    "                graph_def.ParseFromString(file_handle.read())\n",
    "            \n",
    "        tf.import_graph_def(graph_def, name=\"net\")\n",
    "        \n",
    "        if self.tf_version == 1:\n",
    "            self.input_var = tf.get_default_graph().get_tensor_by_name(\n",
    "                \"net/%s:0\" % input_name)\n",
    "            self.output_var = tf.get_default_graph().get_tensor_by_name(\n",
    "                \"net/%s:0\" % output_name)\n",
    "        else: # TF 2\n",
    "            self.input_var = tf.compat.v1.get_default_graph().get_tensor_by_name(\n",
    "                \"%s:0\" % input_name)\n",
    "            self.output_var = tf.compat.v1.get_default_graph().get_tensor_by_name(\n",
    "            \"%s:0\" % output_name)\n",
    "                    \n",
    "        assert len(self.output_var.get_shape()) == 2\n",
    "        assert len(self.input_var.get_shape()) == 4\n",
    "        self.feature_dim = self.output_var.get_shape().as_list()[-1]\n",
    "        self.image_shape = self.input_var.get_shape().as_list()[1:]\n",
    "\n",
    "    def __call__(self, data_x, batch_size=32):\n",
    "        out = np.zeros((len(data_x), self.feature_dim), np.float32)\n",
    "        _run_in_batches(\n",
    "            lambda x: self.session.run(self.output_var, feed_dict=x),\n",
    "            {self.input_var: data_x}, out, batch_size)\n",
    "        return out\n",
    "\n",
    "    \n",
    "def create_box_encoder(model_filename, input_name=\"images\",\n",
    "                       output_name=\"features\", batch_size=32):\n",
    "    image_encoder = ImageEncoder(model_filename, input_name, output_name)\n",
    "    image_shape = image_encoder.image_shape\n",
    "\n",
    "    def encoder(image, boxes):\n",
    "        image_patches = []\n",
    "        for box in boxes:\n",
    "            patch = extract_image_patch(image, box, image_shape[:2])\n",
    "            if patch is None:\n",
    "                print(\"WARNING: Failed to extract image patch: %s.\" % str(box))\n",
    "                patch = np.random.uniform(\n",
    "                    0., 255., image_shape).astype(np.uint8)\n",
    "            image_patches.append(patch)\n",
    "        image_patches = np.asarray(image_patches)\n",
    "        return image_encoder(image_patches, batch_size)\n",
    "\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_in_batches(f, data_dict, out, batch_size):\n",
    "    data_len = len(out)\n",
    "    num_batches = int(data_len / batch_size)\n",
    "\n",
    "    s, e = 0, 0\n",
    "    for i in range(num_batches):\n",
    "        s, e = i * batch_size, (i + 1) * batch_size\n",
    "        batch_data_dict = {k: v[s:e] for k, v in data_dict.items()}\n",
    "        out[s:e] = f(batch_data_dict)\n",
    "    if e < len(out):\n",
    "        batch_data_dict = {k: v[e:] for k, v in data_dict.items()}\n",
    "        out[e:] = f(batch_data_dict)\n",
    "        \n",
    "        \n",
    "def extract_image_patch(image, bbox, patch_shape):\n",
    "    \"\"\"Extract image patch from bounding box.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : ndarray\n",
    "        The full image.\n",
    "    bbox : array_like\n",
    "        The bounding box in format (x, y, width, height).\n",
    "    patch_shape : Optional[array_like]\n",
    "        This parameter can be used to enforce a desired patch shape\n",
    "        (height, width). First, the `bbox` is adapted to the aspect ratio\n",
    "        of the patch shape, then it is clipped at the image boundaries.\n",
    "        If None, the shape is computed from :arg:`bbox`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ndarray | NoneType\n",
    "        An image patch showing the :arg:`bbox`, optionally reshaped to\n",
    "        :arg:`patch_shape`.\n",
    "        Returns None if the bounding box is empty or fully outside of the image\n",
    "        boundaries.\n",
    "\n",
    "    \"\"\"\n",
    "    bbox = np.array(bbox)\n",
    "    if patch_shape is not None:\n",
    "        # correct aspect ratio to patch shape\n",
    "        target_aspect = float(patch_shape[1]) / patch_shape[0]\n",
    "        new_width = target_aspect * bbox[3]\n",
    "        bbox[0] -= (new_width - bbox[2]) / 2\n",
    "        bbox[2] = new_width\n",
    "\n",
    "    # convert to top left, bottom right\n",
    "    bbox[2:] += bbox[:2]\n",
    "    bbox = bbox.astype(int)\n",
    "\n",
    "    # clip at image boundaries\n",
    "    bbox[:2] = np.maximum(0, bbox[:2])\n",
    "    bbox[2:] = np.minimum(np.asarray(image.shape[:2][::-1]) - 1, bbox[2:])\n",
    "    if np.any(bbox[:2] >= bbox[2:]):\n",
    "        return None\n",
    "    sx, sy, ex, ey = bbox\n",
    "    image = image[sy:ey, sx:ex]\n",
    "    image = cv2.resize(image, tuple(patch_shape[::-1]))\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER_PATH = \"./models/mars/mars-small128.pb\"\n",
    "ENCODER_BATCH_SIZE = 32\n",
    "ENCODER_INPUT_NAME = \"images\"\n",
    "ENCODER_OUTPUT_NAME = \"features\"\n",
    "\n",
    "image_encoder = ImageEncoder(ENCODER_PATH, ENCODER_INPUT_NAME, ENCODER_OUTPUT_NAME)\n",
    "encoder = create_box_encoder(ENCODER_PATH, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_cosine_distance = 0.2\n",
    "nn_budget = 100\n",
    "\n",
    "metric = nn_matching.NearestNeighborDistanceMetric(\n",
    "    \"cosine\", max_cosine_distance, nn_budget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create object detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cav.detection import ObjectDetector\n",
    "import cv2\n",
    "#MODEL_PATH = '../models/efficientdet_d4_20200729/inference/saved_model/'\n",
    "#MODEL_PATH = '../CarDetection/models/tf1/output_inference_graph_20200729/saved_model/'\n",
    "#MODEL_PATH = '../../MoveOver/models/frcnn/'\n",
    "#MODEL_PATH = './models/cav/'\n",
    "MODEL_PATH = './models/frcnninference/saved_model/'\n",
    "od = ObjectDetector(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create params and map objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Parameters()\n",
    "params.generateParameters('./config/params.json')\n",
    "mymap = Map('./images/SkyView.jpg', './config/icons.json', params)\n",
    "plt.imshow(mymap.getMap(), interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logging parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPARE_VISUALIZATION = False ### Temporary and ugly - Should be cleaned soon\n",
    "SAVE_FRAMES = False # Doesn't work yet, an idea how to correct PREPARE_VISUALIZATION\n",
    "SAVE_VIDEO = False # Doesn't work yet, an idea how to correct PREPARE_VISUALIZATION\n",
    "\n",
    "LOG_DIR = 'logs'\n",
    "SAVE_LOG = None #### Saves logs with all detected objects (path to file or none)\n",
    "SAVE_LOG = 'log.csv'\n",
    "SAVE_EMPTY_FRAMES = None ### Folder where empty frames shall be saved\n",
    "#SAVE_EMPTY_FRAMES = './empty_frames'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_X = 720\n",
    "VIDEO_Y = 480\n",
    "FRAMES_SEC = 15\n",
    "\n",
    "MAX_BOXES_TO_DRAW = 20\n",
    "MIN_SCORE_THRESH = 0.5\n",
    "IOU_COMMON_THRESHOLD = 0.50\n",
    "NOT_DETECTED_TRHESHOLD = 1\n",
    "\n",
    "MAPSHAPE = mymap.getMap().shape\n",
    "MAP_RESIZE = 2\n",
    "BSM_X = 0\n",
    "\n",
    "RESIZE = False\n",
    "\n",
    "\n",
    "def adjust_image_size(video_x, video_y, map_resize = MAP_RESIZE):\n",
    "      global VIDEO_X\n",
    "      global VIDEO_Y \n",
    "      global MAP_RESIZE\n",
    "      global FINAL_X\n",
    "      global FINAL_Y\n",
    "\n",
    "      VIDEO_X = video_x\n",
    "      VIDEO_Y = video_y\n",
    "      MAP_RESIZE = map_resize\n",
    "\n",
    "      print ('Y dimension of map is {:.3f} larger than Y dimension of the video'\n",
    "            .format(MAPSHAPE[0] / VIDEO_Y))\n",
    "\n",
    "\n",
    "      print ('Y dimension of map is {:.3f} larger than Y dimension of the video. Size of the map is reduced {} times.'\n",
    "            .format(MAPSHAPE[0] / VIDEO_Y, MAP_RESIZE))\n",
    "\n",
    "\n",
    "      FINAL_X = VIDEO_X + int(MAPSHAPE[1] / MAP_RESIZE) + BSM_X\n",
    "      FINAL_Y = max(VIDEO_Y, int(MAPSHAPE[0] / MAP_RESIZE))\n",
    "\n",
    "      print ('Video size: [{}, {}], Final size: [{}, {}]'\n",
    "            .format(VIDEO_X, VIDEO_Y, FINAL_X, FINAL_Y))\n",
    "\n",
    "adjust_image_size(VIDEO_X, VIDEO_Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (MAPSHAPE[0] / VIDEO_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cap = cv2.VideoCapture('rtmp://170.93.143.157/rtplive/c5ff65d2008900a1004f823633235daa')\n",
    "#cap = cv2.VideoCapture('../videos/Corona 24H cam1.avi')\n",
    "\n",
    "# Kaveh's ITERIS camera\n",
    "cap = cv2.VideoCapture() \n",
    "cap.open(\"rtsp://10.228.17.253/2\")\n",
    "\n",
    "# Local Camera\n",
    "#cap = cv2.VideoCapture(0)\n",
    "  \n",
    "\n",
    "# RITIS feed, 8/2023\n",
    "#cap = cv2.VideoCapture()\n",
    "#cap.open('rtmp://cctv.ritis.org/vod/CHART_CCTV_000109f6004b00a6004af03676235daa.vod')\n",
    "\n",
    "video_x = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "video_y = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "adjust_image_size(video_x, video_y)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "\n",
    "prepare_visualization_base = PREPARE_VISUALIZATION\n",
    "\n",
    "if PREPARE_VISUALIZATION:\n",
    "    if RESIZE:\n",
    "        out = cv2.VideoWriter('Test1_output.avi',fourcc, 2*FRAMES_SEC, (int(FINAL_X/2), int(FINAL_Y/2)))\n",
    "    else:\n",
    "        out = cv2.VideoWriter('Test1_output.avi',fourcc, 2*FRAMES_SEC, (int(FINAL_X), int(FINAL_Y)))\n",
    "else:\n",
    "    out = None\n",
    "\n",
    "\n",
    "if not os.path.exists(LOG_DIR):\n",
    "    os.makedirs(LOG_DIR)\n",
    "\n",
    "objects = []\n",
    "\n",
    "results = []\n",
    "colors = {}\n",
    "\n",
    "\n",
    "tracker = Tracker(metric)\n",
    "\n",
    "i = 0\n",
    "t = time()\n",
    "\n",
    "with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "    if PUSH_BSM:\n",
    "        s.connect((HOST, PORT))\n",
    "    while cap.isOpened():\n",
    "        t2 = max(time() - t, 0.1)\n",
    "        sys.stdout.write('{} frames done in {:.1f} seconds ({:.2f} frames/sec)    \\r'.format(\n",
    "            i, t2, i/t2, 0.1))        \n",
    "\n",
    "        ret, image = cap.read()\n",
    "        if image is None:\n",
    "            print (f'IMAGE IS NONE for frame {i}           !!!') # DEBUG\n",
    "            i += 1\n",
    "            continue\n",
    "        \n",
    "        boxes, scores, classes = od.detect(image) \n",
    "        if len(boxes) >= 1:\n",
    "            print (f'{len(boxes)} boxes detected on frame {i}.                            ') # DEBUG\n",
    "\n",
    "            boxes_array = [[box.xLeft, box.yTop, box.xRight - box.xLeft, box.yBottom - box.yTop] for box in boxes]\n",
    "            boxes_array = np.array(boxes_array)\n",
    "            bgr_image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "            features = encoder(bgr_image, boxes_array)\n",
    "            detections = []\n",
    "\n",
    "            for box, score, objClass, f_vector in zip(boxes, scores, classes, features):\n",
    "                detection = Detection(\n",
    "                    [box.xLeft, box.yTop, box.xRight - box.xLeft, box.yBottom - box.yTop], #BBox\n",
    "                    score, f_vector,\n",
    "                    objClass\n",
    "                )\n",
    "                detection.bbox = box\n",
    "                detections.append(detection)\n",
    "\n",
    "            tracker.predict()\n",
    "            tracker.update(detections)                \n",
    "            \n",
    "            # Added to save only important frames DELETE LATER\n",
    "            PREPARE_VISUALIZATION = True\n",
    "        else:\n",
    "            tracker.predict()\n",
    "            PREPARE_VISUALIZATION = prepare_visualization_base\n",
    "            \n",
    "        plotboxes = []\n",
    "        plotcolors = []\n",
    "        objects = []\n",
    "\n",
    "        if len(tracker.tracks) >= 1:\n",
    "            for track in tracker.tracks:\n",
    "                if not track.is_confirmed() or track.time_since_update > 1:\n",
    "                    continue\n",
    "\n",
    "                if False:\n",
    "                    bbox = track.to_tlwh()\n",
    "                    results.append([\n",
    "                        i, track.track_id, bbox[0], bbox[1], bbox[2], bbox[3]])\n",
    "\n",
    "\n",
    "                obj = track.trackedObject\n",
    "\n",
    "                if obj is not None:\n",
    "                    plotbox = obj.bboxes[-1]\n",
    "                    plotbox.trackId = track.track_id\n",
    "                    plotboxes.append(plotbox)\n",
    "                    plotcolors.append(obj.color)\n",
    "                    objects.append(obj)\n",
    "                    \n",
    "\n",
    "            if len(plotboxes) >= 1:\n",
    "                vid = plotBoxes(image, plotboxes, colors=plotcolors)\n",
    "            else:\n",
    "                vid = image.copy()\n",
    "                mapimg = mymap.getMap()\n",
    "\n",
    "            if PREPARE_VISUALIZATION:\n",
    "                mapimg = mymap.addObjects(objects)        \n",
    "        elif PREPARE_VISUALIZATION:\n",
    "                vid = image.copy()\n",
    "                mapimg = mymap.getMap()\n",
    "                    \n",
    "        # Adding map\n",
    "        if PREPARE_VISUALIZATION:\n",
    "            if MAP_RESIZE != 1: # Reducing the size of the map\n",
    "                width = int(mapimg.shape[1] / MAP_RESIZE)\n",
    "                height = int(mapimg.shape[0] / MAP_RESIZE)\n",
    "                dim = (width, height)\n",
    "                # resize image\n",
    "                mapimg = cv2.resize(mapimg, dim, interpolation = cv2.INTER_AREA)                   \n",
    "                    \n",
    "            final_image = np.zeros((FINAL_Y, FINAL_X,3),dtype=np.uint8)\n",
    "\n",
    "            final_image[:VIDEO_Y, :VIDEO_X, :] = vid\n",
    "            final_image[:mapimg.shape[0], VIDEO_X:VIDEO_X + mapimg.shape[1], :] = mapimg  \n",
    "\n",
    "        if (BSM_X > 0) & PREPARE_VISUALIZATION:\n",
    "            if len(objects) > 0:\n",
    "                obj = objects[0]\n",
    "                color = obj.color\n",
    "                bsmimg = bsmImg(obj.getBsm(params=params), framecolor=color)\n",
    "                final_image[:bsmimg.shape[0], VIDEO_X + mapimg.shape[1]:, :] =  bsmimg\n",
    "\n",
    "            if len(objects) > 1:\n",
    "                obj = objects[1]\n",
    "                color = obj.color\n",
    "                bsmimg = bsmImg(obj.getBsm(params=params), framecolor=color)\n",
    "                #final_image[bsmimg.shape[0]+10:2*bsmimg.shape[0]+10, VIDEO_X + mapimg.shape[1]:, :] =  bsmimg\n",
    "\n",
    "        if PREPARE_VISUALIZATION & RESIZE: # Resize image\n",
    "            width = int(final_image.shape[1] / 2)\n",
    "            height = int(final_image.shape[0] / 2)\n",
    "            dim = (width, height)\n",
    "            # resize image\n",
    "            final_image = cv2.resize(final_image, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "        if PREPARE_VISUALIZATION:\n",
    "            cv2.imwrite('./tmp/im_{}.jpg'.format(str(i).zfill(6)), final_image)\n",
    "            if out is not None:\n",
    "                out.write(final_image)            \n",
    "                \n",
    "            \n",
    "            \n",
    "        bsm_list = []\n",
    "        \n",
    "        if len(objects) > 0:\n",
    "            for obj in objects:\n",
    "                bsm_list.append(obj.getBsm(retDic = False, params=params, roundValues = True, includeNone = False))\n",
    "\n",
    "            #print (bsm_list)\n",
    "            if PUSH_BSM:\n",
    "                data = sendBsm(s, json.dumps(bsm_list))\n",
    "                #print (\"Response: {}\\n\".format(data))            \n",
    "\n",
    "                \n",
    "            if SAVE_EMPTY_FRAMES is not None:\n",
    "                cv2.imwrite('{}/im_{}.jpg'.format(SAVE_EMPTY_FRAMES, str(i).zfill(4)), image)\n",
    "                \n",
    "            if SAVE_LOG is not None:\n",
    "                logfile_path = os.path.join(LOG_DIR, SAVE_LOG)\n",
    "                with open(logfile_path, 'a') as logfile:\n",
    "                    for obj in objects:\n",
    "                        line = '{},{},{}'.format(i,time(),obj.getParams(asCsv=True))                               \n",
    "                        print(line,file=logfile)                    \n",
    "                                \n",
    "        i = i+1\n",
    "        if False: #i > 5* FRAMES_SEC:\n",
    "            if False:\n",
    "                f = open('tmp_tracking_results_demo.txt', 'w')\n",
    "                for row in results:\n",
    "                    print('%d,%d,%.2f,%.2f,%.2f,%.2f,1,-1,-1,-1' % (\n",
    "                        row[0], row[1], row[2], row[3], row[4], row[5]),file=f)        \n",
    "            break\n",
    "                  \n",
    "            \n",
    "                        \n",
    "t_total = time() - t                            \n",
    "print('\\n\\n{} frames done in {:.1f} seconds ({:.2f} frames/sec)'.format(\n",
    "    i, t_total, i/t_total))                             \n",
    "cap.release()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
