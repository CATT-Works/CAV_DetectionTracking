{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprare configs\n",
    "\n",
    "This notebook supports the process of preparing config files.\n",
    "The goals of the notebooks are as follows:\n",
    "- extracting selected frame(s) from the video\n",
    "- setting ant testing unwrapping parameters (camera view -> bird's eye view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dispimges(im1, im2, BGR2RGB1=True, BGR2RGB2=True, im1_title='Original Image', im2_title = 'Processed image', fontsize=20):\n",
    "    iscolor1 = len(im1.shape) > 2\n",
    "    iscolor2 = len(im2.shape) > 2 \n",
    "    if BGR2RGB1 and iscolor1:\n",
    "        im1 = cv2.cvtColor(im1, cv2.COLOR_BGR2RGB)\n",
    "    if BGR2RGB2 and iscolor2:\n",
    "        im2 = cv2.cvtColor(im2, cv2.COLOR_BGR2RGB)\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "    if iscolor1:\n",
    "        ax1.imshow(im1)\n",
    "    else:\n",
    "        ax1.imshow(im1, cmap='gray')\n",
    "    ax1.set_title(im1_title, fontsize=fontsize)\n",
    "    if iscolor2:\n",
    "        ax2.imshow(im2)\n",
    "    else:\n",
    "        ax2.imshow(im2, cmap='gray')\n",
    "    ax2.set_title(im2_title, fontsize=fontsize)\n",
    "    return ax1, ax2\n",
    "\n",
    "def extract_frame(video_path = None, cap = None, frameno = 1, dest_file = None, display = True):\n",
    "    \"\"\"\n",
    "    Extracts (and optionally saves) one frame from the video\n",
    "    Arguments:\n",
    "        video_path - path to the video\n",
    "        cap        - captured video (results of cv2.VideoCapture). Works only if video_path is None\n",
    "        frameno    - number of frame to be extracted\n",
    "        dest_file  - where should the frame be saved\n",
    "        display    - it True, the frame is displayed        \n",
    "    \"\"\"\n",
    "    if video_path is None:\n",
    "        if cap is None:\n",
    "             raise Exception('Either video_path or cap must be set.')\n",
    "    else:\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        \n",
    "    cap.set(1,frameno);\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    ret, image = cap.read()\n",
    "    if dest_file is not None:\n",
    "        cv2.imwrite(dest_file,image)\n",
    "    \n",
    "    if display:\n",
    "        im2 = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        f = plt.figure(figsize=(20, 10))\n",
    "        plt.imshow(im2)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_FILE = '/data/MoveOver/Videos/I97-New Cut Road HH 3-4-21.mp4'\n",
    "extract_frame(VIDEO_FILE, frameno = 100, dest_file = './frame_100.jpg');\n",
    "extract_frame(VIDEO_FILE, frameno = 100, dest_file = './frame_115.jpg');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Points for source (camera view) and destination (image view)\n",
    "First four points are used for unwrapping, the rest is just display at tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = np.float32([\n",
    "        [446, 1016],\n",
    "        [1231, 970],\n",
    "        [842, 759],\n",
    "        [1377, 787],\n",
    "        [1023, 299],\n",
    "    ])\n",
    "    \n",
    "DST = np.float32([\n",
    "        [110, 37],\n",
    "        [79, 104],\n",
    "        [174, 220],\n",
    "        [127, 236],\n",
    "        [620, 1177],\n",
    "    ])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = cv2.getPerspectiveTransform(SRC[:4], DST[:4])\n",
    "Minv = cv2.getPerspectiveTransform(DST[:4], SRC[:4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_point(points, M, img1_path, img2_path):\n",
    "    src = np.array([points], dtype='float32')\n",
    "\n",
    "    print (src)\n",
    "    trans = cv2.perspectiveTransform(src, M)\n",
    "    \n",
    "    img = cv2.imread(img1_path)\n",
    "    mapimg = cv2.imread(img2_path)\n",
    "    \n",
    "    ax1, ax2 = dispimges(img, mapimg)\n",
    "\n",
    "    if True: #show points\n",
    "        for coor in src[0]:\n",
    "            ax1.plot(coor[0], coor[1], '.', color='red')\n",
    "        for coor in trans[0]:\n",
    "            ax2.plot(coor[0], coor[1], '.', color='red')\n",
    "    return trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = display_point(SRC, M, './frame_100.jpg', 'I97_NewCutRoad.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = display_point(DST, Minv, 'I97_NewCutRoad.jpg',  './frame_100.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below displays the parameters in the format that can be pasted directly to config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('  \"cameraPoints\" : [[{}, {}], [{}, {}], [{}, {}], [{}, {}]],'.format(\n",
    "    SRC[0][0], SRC[0][1], SRC[1][0], SRC[1][1], SRC[2][0], SRC[2][1],SRC[3][0], SRC[3][1]))\n",
    "\n",
    "print('  \"birdEyePoints\" : [[{}, {}], [{}, {}], [{}, {}], [{}, {}]],'.format(\n",
    "    DST[0][0], DST[0][1], DST[1][0], DST[1][1], DST[2][0], DST[2][1], DST[3][0], DST[3][1])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lane masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK_PATH = '../images/lane_masks/I97_NewCutRoad_Mask.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "mask = (255*plt.imread(MASK_PATH)).astype(int)\n",
    "if (len(mask.shape) == 3) and (mask.shape[2] > 1):\n",
    "    #mask = np.sum(mask, axis=2)\n",
    "    mask = mask[:, :, 0]\n",
    "plt.imshow(mask, cmap='gray')\n",
    "list(np.unique(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
